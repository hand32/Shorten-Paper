## Papers Directory Path ##
## Defaults
##  PAPERS_INPUT_DIR=./papers_to_be_shorten
##  PAPERS_OUTPUT_DIR=./papers_shorten_result
##  OUTPUT_PREFIX="Shortened_"
PAPERS_INPUT_DIR=./papers_to_be_shorten
PAPERS_OUTPUT_DIR=./papers_shorten_result
OUTPUT_PREFIX="Shortened_"

## LANGUAGE MODEL SETTINGS ##
## Defaults
##  OPENAI_API_KEY=your_api_key  # https://platform.openai.com/account/api-keys
##
##  LANG_MODEL_NAME=gpt-3.5-turbo  # (str) https://platform.openai.com/docs/models/gpt-3-5
##  TEXT_TOKEN_LEN=3000  # (int) https://platform.openai.com/docs/models/gpt-3-5
##
##  MODEL_TEMPERATURE=0.1  # (float) [0, 2]
##  MODEL_TOP_P=0.2  # (float) [0, 1]
##  MODEL_FREQUENCY_PENALTY=0.0  # (float) [-2, 2]
##  MODEL_PRESENCE_PENALTY=0.0  # (float) [-2, 2]
OPENAI_API_KEY=your_api_key

LANG_MODEL_NAME=gpt-3.5-turbo
TEXT_TOKEN_LEN=3000

MODEL_TEMPERATURE=0.1
MODEL_TOP_P=0.2
MODEL_PRESENCE_PENALTY=0.0
MODEL_FREQUENCY_PENALTY=0.0

## TEXT SETTINGS ##
## Defaults
##  SHORTEN_RATIO=0.4  # (float) (0, 1]
##
## Sum of below two TOKEN_RATIOs should be under 1.0.
## Model references previous/next text truncated by each TOKEN_RATIO.
## Low TOKEN_RATIOs can result in efficient token usage, but it may also lead to inconsitancy.
##  PREVIOUS_TEXT_TOKEN_RATIO=0.4  # (float) [0, 1)
##  NEXT_TEXT_TOKEN_RATIO=0.2  # (float) [0, 1)
##
## Description of how the token count be calculated.
## CURRENT_TEXT_TOKEN_CNT = TEXT_TOKEN_LEN * (1 + SHORTEN_RATIO + PREVIOUS_TEXT_TOKEN_RATIO + NEXT_TEXT_TOKEN_RATIO)
## PREVIOUS_TEXT_TOKEN_CNT = CURRENT_TEXT_TOKEN_CNT * PREVIOUS_TEXT_TOKEN_RATIO
## NEXT_TEXT_TOKEN_CNT = CURRENT_TEXT_TOKEN_CNT * NEXT_TEXT_TOKEN_RATIO
## SHORTENED_TEXT_TOKEN_CNT = CURRENT_TEXT_TOKEN_CNT * SHORTEN_RATIO
SHORTEN_RATIO=0.4
PREVIOUS_TEXT_TOKEN_RATIO=0.4
NEXT_TEXT_TOKEN_RATIO=0.2

## SUPPORTED FILE EXTENSIONS FOR PARSING
## ".txt", ".csv", ".pdf", ".doc", ".docx", ".json", ".xml", ".yaml", ".html", ".md", ".tex"
## Implement the extension you want, in 'file_operation_utils.py'.